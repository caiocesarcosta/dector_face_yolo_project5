{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzQfFhZibBXIQj9pgiQ4zr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caiocesarcosta/dector_face_yolo_project5/blob/main/dector_face_yolo_project5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gxc6c1CvsNFf",
        "outputId": "d57ab943-d4d6-42e3-91ed-343534eb5c33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Clonando yolo do github\n",
            "Instalando dependências\n",
            "Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (3.1.44)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (1.26.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=10.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (11.1.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (1.13.1)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (0.20.1+cu124)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (4.67.1)\n",
            "Requirement already satisfied: ultralytics>=8.2.34 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 18)) (8.3.77)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 27)) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 28)) (0.13.2)\n",
            "Requirement already satisfied: setuptools>=70.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 42)) (75.1.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.12)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics>=8.2.34->-r requirements.txt (line 18)) (9.0.0)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics>=8.2.34->-r requirements.txt (line 18)) (2.0.14)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2025.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (3.0.2)\n",
            "Classe 1 iniciada.\n",
            "Classe 2 iniciada.\n",
            "Detectando face da imagem\n",
            "Bounding boxes: [(0.0, 0.495098, 0.517157, 0.980392, 0.955882)]\n",
            "Apresentando Bounding Boxes\n",
            "Formato da imagem JPEG e tamanho (204, 204)\n",
            "Found 56 images belonging to 1 classes.\n",
            "Found 56 images belonging to 1 classes.\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/losses/losses.py:33: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 2/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 3/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 4/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 5/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Modelo treinado\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'FaceClassifier' object has no attribute 'validation_generator'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-37ba4edcc235>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m \u001b[0mreconhecerImagem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-37ba4edcc235>\u001b[0m in \u001b[0;36mreconhecerImagem\u001b[0;34m()\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m   \u001b[0;31m#Apresenta o resultado\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m   \u001b[0mclassificacao\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluateModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassificacao\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Apresentado Resultado do modelo\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'FaceClassifier' object has no attribute 'validation_generator'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import shutil\n",
        "import yaml\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Configurações\n",
        "img_width, img_height = 224, 224 # Redimensiona as imagens para este tamanho\n",
        "face_detection_threshold = 0.5 # Limiar de confiança para detecção facial\n",
        "drive.mount('/content/drive', force_remount=True) # Conecta ao google drive para acessar os arquivos\n",
        "\n",
        "class FaceDetector:\n",
        "    def __init__(self, img_width):\n",
        "        self.repoYoloGitHub = 'https://github.com/ultralytics/yolov5'\n",
        "        self.pretrained_weights = 'yolov5s.pt'  # Usa o modelo pequeno (mais rápido)\n",
        "        self.img_width = img_width\n",
        "        self.cloneRepoistoryYoloGitHub()\n",
        "        self.installDependency()\n",
        "\n",
        "    def cloneRepoistoryYoloGitHub(self):\n",
        "        \"\"\"Clone the yolo repository, from gitHub.\"\"\"\n",
        "        print (\"Clonando yolo do github\")\n",
        "        if not os.path.exists('/content/yolov5'):\n",
        "           clone_command = f\"git clone {self.repoYoloGitHub}\"\n",
        "           os.system(clone_command)  # Use os.system para executar o comando\n",
        "\n",
        "    def installDependency(self):\n",
        "      \"\"\"Install the dependecies.\"\"\"\n",
        "      print (\"Instalando dependências\")\n",
        "      if os.path.exists('/content/yolov5'):\n",
        "        os.chdir('/content/yolov5')\n",
        "        !pip install -r requirements.txt\n",
        "\n",
        "    def detectFaces(self, source, conf_thres=0.5):\n",
        "        \"\"\"Detecta faces em uma imagem e retorna os bounding boxes.\"\"\"\n",
        "        print (\"Detectando face da imagem\")\n",
        "        detect_command = f\"python detect.py --weights {self.pretrained_weights} --img {self.img_width} --conf {conf_thres} --source \\\"{source}\\\" --save-txt\"\n",
        "        os.system(detect_command)  # Use os.system\n",
        "\n",
        "        return self.parseYOLOResults(source) # carrega para a função as informações da imagem\n",
        "\n",
        "    def parseYOLOResults(self, source):\n",
        "        \"\"\"Analisa os resultados do YOLO e retorna os bounding boxes.\"\"\"\n",
        "        results_dir = '/content/yolov5/runs/detect/exp/labels' # Garante que estamos procurando no local correto\n",
        "        base_name = os.path.basename(source).split('.')[0]\n",
        "        results_file = os.path.join(results_dir, base_name + '.txt')\n",
        "        if not os.path.exists(results_file):\n",
        "            print (f\"Aviso: Nenhum objeto detectado {results_dir}!\")\n",
        "            return [] # Retorna uma lista vazia se nenhum arquivo for encontrado\n",
        "\n",
        "        bounding_boxes = []\n",
        "        try:\n",
        "            with open(results_file, 'r') as f:\n",
        "                for line in f:\n",
        "                    data = line.strip().split()\n",
        "                    if len(data) == 5:\n",
        "                        class_id, x_center, y_center, width, height = map(float, data)\n",
        "                        bounding_boxes.append((class_id, x_center, y_center, width, height))\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Arquivo de resultados não encontrado: {results_file}\")\n",
        "        return bounding_boxes\n",
        "\n",
        "class FaceClassifier:\n",
        "    def __init__(self, train_dir, validation_dir, img_width, img_height, num_classes, epochs=10, batch_size=32):\n",
        "      self.train_dir = train_dir\n",
        "      self.validation_dir = validation_dir\n",
        "      self.img_width = img_width\n",
        "      self.img_height = img_height\n",
        "      self.num_classes = num_classes\n",
        "      self.epochs = epochs\n",
        "      self.batch_size = batch_size\n",
        "      self.model = self.createModel()\n",
        "      self.compileModel()\n",
        "\n",
        "    def createModel(self):\n",
        "        \"\"\"Cria o modelo de classificação (CNN).\"\"\"\n",
        "        input_shape = (self.img_width, self.img_height, 3)\n",
        "        model = Sequential([\n",
        "            Conv2D(32, (3, 3), input_shape=input_shape, activation='relu'),\n",
        "            MaxPooling2D(pool_size=(2, 2)),\n",
        "            Conv2D(64, (3, 3), activation='relu'),\n",
        "            MaxPooling2D(pool_size=(2, 2)),\n",
        "            Flatten(),\n",
        "            Dense(128, activation='relu'),\n",
        "            Dropout(0.5),\n",
        "            Dense(self.num_classes, activation='softmax') # Camada de saída\n",
        "        ])\n",
        "        return model\n",
        "\n",
        "    def compileModel(self):\n",
        "        \"\"\"Compila o modelo para treinamento.\"\"\"\n",
        "        self.model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer='adam',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "    def trainModel(self):\n",
        "        \"\"\"Treina o modelo usando os dados do Google Drive.\"\"\"\n",
        "        train_datagen = ImageDataGenerator(\n",
        "            rescale=1. / 255,\n",
        "            shear_range=0.2,\n",
        "            zoom_range=0.2,\n",
        "            horizontal_flip=True,\n",
        "            rotation_range=20)  # Adiciona rotação para aumentar a variabilidade\n",
        "\n",
        "        test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "        train_generator = train_datagen.flow_from_directory(\n",
        "            self.train_dir,\n",
        "            target_size=(self.img_width, self.img_height),\n",
        "            batch_size=self.batch_size,\n",
        "            class_mode='categorical')  # Usar categorical para múltiplas classes\n",
        "\n",
        "        validation_generator = test_datagen.flow_from_directory(\n",
        "            self.validation_dir,\n",
        "            target_size=(self.img_width, self.img_height),\n",
        "            batch_size=self.batch_size,\n",
        "            class_mode='categorical')  # Usar categorical para múltiplas classes\n",
        "\n",
        "        self.history = self.model.fit(\n",
        "            train_generator,\n",
        "            steps_per_epoch=train_generator.samples // self.batch_size,\n",
        "            epochs=self.epochs,\n",
        "            validation_data=validation_generator,\n",
        "            validation_steps=validation_generator.samples // self.batch_size)\n",
        "\n",
        "        return train_generator.class_indices # retorne o resultado das classes para auxílio\n",
        "    def evaluateModel(self, validation_generator):\n",
        "      \"\"\"Função para avaliar o modelo treinado, e gerar um report.\"\"\"\n",
        "      # Depois do treinamento, avaliar o modelo:\n",
        "      loss, accuracy = self.model.evaluate(validation_generator)\n",
        "      print(f\"Perda (Loss): {loss:.4f}\")\n",
        "      print(f\"Precisão (Accuracy): {accuracy:.4f}\")\n",
        "\n",
        "      # Fazer previsões para construir a matriz de confusão e exibir as metricas para a análise do resultado\n",
        "      from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "      val_steps_per_epoch = np.math.ceil(float(validation_generator.samples) / batch_size)\n",
        "      Y_pred = self.model.predict(validation_generator, steps=val_steps_per_epoch)\n",
        "      y_pred = np.argmax(Y_pred, axis=1)\n",
        "      print('Relatório de Classificação')\n",
        "      print(classification_report(validation_generator.classes, y_pred, target_names=validation_generator.class_indices.keys()))\n",
        "\n",
        "def crop_face(image, bbox):\n",
        "    \"\"\"Corta uma face da imagem usando as coordenadas do bounding box.\"\"\"\n",
        "    class_id, x_center, y_center, width_norm, height_norm = bbox\n",
        "    left = int((x_center - width_norm / 2) * 150)\n",
        "    top = int((y_center - height_norm / 2) * 150)\n",
        "    right = int((x_center + width_norm / 2) * 150)\n",
        "    bottom = int((y_center + height_norm / 2) * 150)\n",
        "    return image.crop((left, top, right, bottom))\n",
        "\n",
        "def reconhecerImagem(): # juntando as funções para gerar o treinamento\n",
        "  \"\"\"Implementa o reconhecimento facil \"\"\"\n",
        "  # Configurações\n",
        "  train_dir = '/content/drive/MyDrive/the_big_bang_theory/data/train/' # Pasta com as fotos para o treino\n",
        "  validation_dir = '/content/drive/MyDrive/the_big_bang_theory/data/train/'  # Pasta com as fotos de validação\n",
        "  img_width, img_height = 224, 224 # Redimensiona as imagens para este tamanho\n",
        "  num_classes = len(os.listdir(train_dir)) # Ajuste conforme o número de pessoas\n",
        "  batch_size = 32\n",
        "  epochs = 5\n",
        "\n",
        "  # Treinamento do modelo\n",
        "  # Verifique se há imagens no diretório de treinamento\n",
        "  if len(os.listdir(train_dir)) == 0:\n",
        "    print(f\"Erro: O diretório de treinamento '{train_dir}' está vazio. Verifique o caminho.\")\n",
        "    return  # Sai da função se o diretório estiver vazio\n",
        "\n",
        "\n",
        "\n",
        "  # Inicializa o Detector de Faces\n",
        "  detector = FaceDetector(img_width)\n",
        "  print(\"Classe 1 iniciada.\")\n",
        "\n",
        "  # Cria as pastas para o modelo para auxiliar no treinamento\n",
        "  faces_dir = '/content/coco_yolo/faces'\n",
        "\n",
        "  #Verifica se a pasta existe, e cria as pastas\n",
        "  if not os.path.exists(faces_dir):\n",
        "      os.makedirs(faces_dir, exist_ok = True)\n",
        "\n",
        "  # Inicializa o Classificador de Faces\n",
        "  classificacao = FaceClassifier(train_dir, validation_dir, img_width, img_height, num_classes, epochs, batch_size)\n",
        "  print(\"Classe 2 iniciada.\")\n",
        "\n",
        "  # Carrega a imagem de exemplo\n",
        "  #test_image = '/content/yolov5/data/images/bus.jpg'  # imagem de exemplo do yolo\n",
        "  test_image = '/content/drive/MyDrive/the_big_bang_theory/data/train/penny/penny1.jpg' # imagem que está no google drive\n",
        "\n",
        "  # Detecta faces na imagem de teste\n",
        "  bounding_boxes = detector.detectFaces(test_image)\n",
        "\n",
        "  # Imprimi Bounding boxes encontrados\n",
        "  print (f\"Bounding boxes: {bounding_boxes}\")\n",
        "  # Imagens que as funções não encontrassem o que precisavam, não seriam mais exibidas, já que a detecção seria feita por um novo teste\n",
        "  if bounding_boxes:\n",
        "      print(\"Apresentando Bounding Boxes\")\n",
        "       # Apresenta os dados, caso positivo\n",
        "      # Carrega a imagem novamente\n",
        "      img_open = Image.open(test_image)\n",
        "      print (f\"Formato da imagem {img_open.format} e tamanho {img_open.size}\")\n",
        "  else:\n",
        "      print(\"Nenhuma anotação foi encontrada nessa imagem, tente outras imagens. O programa se encerrará.\")\n",
        "      return\n",
        "\n",
        "  # Treinamento do modelo\n",
        "  class_name = classificacao.trainModel()\n",
        "  print(\"Modelo treinado\")\n",
        "\n",
        "  #Apresenta o resultado\n",
        "  classificacao.evaluateModel(classificacao.validation_generator)\n",
        "  print(\"Apresentado Resultado do modelo\")\n",
        "\n",
        "  # Corta as faces e as classifica\n",
        "  for i, bbox in enumerate(bounding_boxes):\n",
        "      #Corta a imagem com as dimensões\n",
        "      face_crop = crop_face(img_open, bbox)\n",
        "       # Converte para RGB, para evitar erros\n",
        "      if face_crop.mode != \"RGB\":\n",
        "        face_crop = face_crop.convert(\"RGB\")\n",
        "      #Salva as imagens na pasta\n",
        "      face_crop.save(os.path.join(faces_dir, f\"face_{i}.jpg\"))\n",
        "      print (f\"Imagem {i} salva\")\n",
        "\n",
        "#Função para cortar as imagens.\n",
        "def crop_face(image, bbox):\n",
        "    \"\"\"Corta uma face da imagem usando as coordenadas do bounding box.\"\"\"\n",
        "    class_id, x_center, y_center, width_norm, height_norm = bbox\n",
        "    left = int((x_center - width_norm / 2) * 150)\n",
        "    top = int((y_center - height_norm / 2) * 150)\n",
        "    right = int((x_center + width_norm / 2) * 150)\n",
        "    bottom = int((y_center + height_norm / 2) * 150)\n",
        "    return image.crop((left, top, right, bottom))\n",
        "\n",
        "reconhecerImagem()\n"
      ]
    }
  ]
}